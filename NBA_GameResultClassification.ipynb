{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f11e00a4-645f-43ba-a1ec-7914fc51793f",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76357488-dd98-4b6b-a03d-2ff8f0bf1926",
   "metadata": {},
   "source": [
    "There are two datasets in this projects. First one contains relative score differential and total score of each game of each team scrapped by me from ESPN. The other dataset is the \"Advanced Team Statistics\" of each team againg scrapped by me from Fox Sport on each day of the 2018-2019 season. You can go over databases, we have shared them. The statistics datasets have almost every predictor we want to train our model except the Home/Away information which we will calculate using schedule/score dataset and add it to our training dataset. (Datasets won't be shared within project files, this notebook is only for giving the intuition of opponent based double checked prediction approach and sharing the results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6de82b-d4fa-4500-9895-3160f933d7e1",
   "metadata": {},
   "source": [
    "Although we have data of the whole season the model we want to build is going to use only the previous data to predict a game. For example if we want to predict 44th game of the season for Timberwolves the model will only use previous games to train and will predict the result of 44th game. Besides, model will not use the statistics of the team that we want to predict its game but its opponents'. What I mean is we will use previous opponents statistics as explanatory variables and the score of the game against that opponent as response variable and to predict 44th game of the season for Timberwolves we will give the statistics of the opponent to the model to predict the result of that game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabb048d-0213-4250-9d1e-cf4e80e9e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5861bcf1-ef6a-4448-8113-b70f43468ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to databases and fetch all \n",
    "con_schedule = sqlite3.connect(\"schedule_scores.db\")\n",
    "cursor_schedule = con_schedule.cursor()\n",
    "\n",
    "con_stats = sqlite3.connect(\"team_stats.db\")\n",
    "cursor_stats = con_stats.cursor()\n",
    "\n",
    "# List of 30 teams and city name dictionary to match the names used by ESPN and FoxSport\n",
    "teams = [\"CHA\",\"PHI\",\"TOR\",\"BOS\",\"CLE\",\"IND\",\"WSH\",\"MIL\",\"MIA\",\"DET\",\"NY\",\"CHI\",\"ORL\",\"BKN\",\"ATL\",\"HOU\",\"GS\",\"POR\",\"NO\",\"MIN\",\"SA\",\"OKC\",\"DEN\",\"LAC\",\"UTA\",\"LAL\",\"SAC\",\"DAL\",\"PHX\",\"MEM\"]\n",
    "city_dic = {\"atl\":\"Atlanta\",\"bkn\": \"Brooklyn\" ,\"bos\": \"Boston\", \"cha\":\"Charlotte\", \"chi\":\"Chicago\", \"cle\": \"Cleveland\", \"dal\": \"Dallas\", \"den\": \"Denver\", \"det\":\"Detroit\",\"gs\":\"Golden State\", \"hou\": \"Houston\", \"ind\":\"Indiana\",\"lac\":\"LA\", \"lal\": \"Los Angeles\",\"mem\": \"Memphis\",\"mia\":\"Miami\",\"mil\":\"Milwaukee\",\"min\":\"Minnesota\",\"no\":\"New Orleans\",\"ny\":\"New York\",\"okc\":\"Oklahoma City\",\"orl\":\"Orlando\",\"phi\":\"Philadelphia\",\"phx\":\"Phoenix\",\"por\":\"Portland\",\"sa\":\"San Antonio\",\"sac\":\"Sacramento\",\"tor\":\"Toronto\",\"uta\":\"Utah\",\"wsh\":\"Washington\" }\n",
    "\n",
    "# Fetching the schedules of each team\n",
    "schedules = {}\n",
    "for team in teams:\n",
    "    cursor_schedule.execute(\"SELECT * FROM {}\".format(team.lower()))\n",
    "    schedules[team.lower()] = cursor_schedule.fetchall()\n",
    "\n",
    "# Fetching the stats of each team\n",
    "stats = {}\n",
    "for team in teams:\n",
    "    cursor_stats.execute(\"SELECT * FROM {}\".format(team.lower()))\n",
    "    stats[team.lower()] = cursor_stats.fetchall()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e6a4f6-ceff-47e8-b070-522f86edc324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Date</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Score</th>\n",
       "      <th>TotalScore</th>\n",
       "      <th>Date_of_stat</th>\n",
       "      <th>GamesPlayed</th>\n",
       "      <th>Home/Away(1/0)</th>\n",
       "      <th>OffRtg</th>\n",
       "      <th>DefRtg</th>\n",
       "      <th>...</th>\n",
       "      <th>TrueS</th>\n",
       "      <th>Efg</th>\n",
       "      <th>TurnOver</th>\n",
       "      <th>OffReb</th>\n",
       "      <th>FtFga</th>\n",
       "      <th>EfgAllow</th>\n",
       "      <th>TurnOvAllow</th>\n",
       "      <th>DefRebAllow</th>\n",
       "      <th>FtFgaAllow</th>\n",
       "      <th>WinLose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>New York</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2018-10-31 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.5</td>\n",
       "      <td>110.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.489</td>\n",
       "      <td>11.7</td>\n",
       "      <td>24.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.544</td>\n",
       "      <td>14.5</td>\n",
       "      <td>75.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>2018-11-02 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>101.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.512</td>\n",
       "      <td>12.4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.524</td>\n",
       "      <td>16.4</td>\n",
       "      <td>82.6</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>22.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2018-11-01 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>117.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.489</td>\n",
       "      <td>12.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.585</td>\n",
       "      <td>13.6</td>\n",
       "      <td>70.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>7.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2018-10-31 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.8</td>\n",
       "      <td>113.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.507</td>\n",
       "      <td>13.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.568</td>\n",
       "      <td>14.2</td>\n",
       "      <td>76.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-10-27</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2018-10-31 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.7</td>\n",
       "      <td>118.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.535</td>\n",
       "      <td>12.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.539</td>\n",
       "      <td>10.9</td>\n",
       "      <td>82.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Game       Date   Opponent  Score  TotalScore         Date_of_stat  \\\n",
       "0     1 2018-10-17   New York  -19.0       233.0  2018-10-31 00:00:00   \n",
       "1     2 2018-10-19    Memphis  -14.0       248.0  2018-11-02 00:00:00   \n",
       "2     3 2018-10-21  Cleveland   22.0       244.0  2018-11-01 00:00:00   \n",
       "3     4 2018-10-24     Dallas    7.0       215.0  2018-10-31 00:00:00   \n",
       "4     5 2018-10-27    Chicago  -12.0       182.0  2018-10-31 00:00:00   \n",
       "\n",
       "  GamesPlayed  Home/Away(1/0) OffRtg DefRtg  ...  TrueS    Efg TurnOver  \\\n",
       "0           7             0.0  106.5  110.5  ...  0.522  0.489     11.7   \n",
       "1           7             0.0  105.5  101.8  ...  0.557  0.512     12.4   \n",
       "2           8             0.0  109.8  117.7  ...  0.538  0.489     12.7   \n",
       "3           7             1.0  107.8  113.5  ...  0.542  0.507     13.2   \n",
       "4           7             1.0  108.7  118.2  ...  0.567  0.535     12.9   \n",
       "\n",
       "  OffReb FtFga EfgAllow TurnOvAllow DefRebAllow FtFgaAllow WinLose  \n",
       "0   24.2  16.2    0.544        14.5        75.8       21.3       0  \n",
       "1   17.4  25.7    0.524        16.4        82.6       20.2       0  \n",
       "2   29.6  22.7    0.585        13.6        70.4       19.9       1  \n",
       "3   23.9  19.4    0.568        14.2        76.1       23.4       1  \n",
       "4   17.5  20.1    0.539        10.9        82.5       22.3       0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will write a function that creates x and y matrices to predict specific game\n",
    "# To do this we are going add statistics of the opponents to schedule/score dataset \n",
    " \n",
    "def get_datasets(schedules,stats):\n",
    "    \n",
    "    datasets = {}\n",
    "    for team in teams:\n",
    "        team = team.lower()\n",
    "        schedule = schedules[team]\n",
    "\n",
    "        schedule_df = pd.DataFrame(schedule, columns=['Game', 'Date', 'Opponent','Home/Away(1/0)','Score','TotalScore'])\n",
    "        # Date column should be formatted from 'Oct 19 2019' to pandas date\n",
    "        schedule_df['Date'] = pd.to_datetime(schedule_df['Date'],format='%b %d %Y')\n",
    "\n",
    "        # We are going to add each opponents statisctis to that dataframe and than we are going to combine schedule_df and stats_df\n",
    "        stats_df = pd.DataFrame(columns=[\"Date_of_stat\",\"GamesPlayed\",\"OffRtg\",\"DefRtg\",\"Pace\",\"FtRate\",\"ThreeFgTend\",\n",
    "        \"TrueS\",\"Efg\",\"TurnOver\",\"OffReb\",\"FtFga\",\"EfgAllow\",\"TurnOvAllow\",\"DefRebAllow\",\"FtFgaAllow\"])\n",
    "\n",
    "        # To fill stats_df we are goint to itterate over the rows of schedule_df.\n",
    "        for index, row in schedule_df.iterrows():\n",
    "\n",
    "            # team_stats.db has long city names instead of short ones like in the schedule_scores.db \n",
    "            # therefore a dictionary is used to match the team names ex. opponent_ = \"Atlanta\" -> opponent = \"atl\"\n",
    "            opponent_ = row[\"Opponent\"]\n",
    "            opponent = list(filter(lambda x: x[1] == opponent_,list(city_dic.items())))[0][0]\n",
    "\n",
    "            opponent_stats_table = stats[opponent]\n",
    "            opponent_stats_df = pd.DataFrame(opponent_stats_table,columns=[\"Date_of_stat\",\"GamesPlayed\",\"OffRtg\",\"DefRtg\",\"Pace\",\"FtRate\",\"ThreeFgTend\",\n",
    "        \"TrueS\",\"Efg\",\"TurnOver\",\"OffReb\",\"FtFga\",\"EfgAllow\",\"TurnOvAllow\",\"DefRebAllow\",\"FtFgaAllow\"])\n",
    "            opponent_stats_df['Date_of_stat'] = pd.to_datetime(opponent_stats_df['Date_of_stat'],format='%b %d %Y')\n",
    "\n",
    "            # We have a date from schedule and we basicaly try to find the statistics row that have the most \n",
    "            # similar date with schedule because the not every day's statistics are gathered\n",
    "            date = row[\"Date\"]\n",
    "            stats_at_date = opponent_stats_df.iloc[opponent_stats_df.Date_of_stat.searchsorted(date-pd.DateOffset(days=1))].to_frame().T\n",
    "            stats_df = pd.concat([stats_df,stats_at_date])\n",
    "\n",
    "\n",
    "        df = pd.concat([schedule_df.reset_index(drop=True),stats_df.reset_index(drop=True)], axis=1)\n",
    "        # Changing the position of Home/Away column to make easier to chose x and y matrices\n",
    "        homeAway_column = df.pop('Home/Away(1/0)')\n",
    "        df.insert(7, 'Home/Away(1/0)', homeAway_column)\n",
    "\n",
    "        df['WinLose'] = np.where(df['Score'] >= 0, 1, 0)\n",
    "        \n",
    "        datasets[team] = df\n",
    "    return datasets\n",
    "\n",
    "datasets = get_datasets(schedules,stats)\n",
    "datasets[\"atl\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce44426-9748-49dc-9618-037b75041202",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "The get_train_test function takes the last n games we specified as train set and row with the game that we want to predict as test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45d70c3-84af-48ef-923d-92d246217b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df,game_number,last_n_games):\n",
    "    \n",
    "    if game_number <= last_n_games:\n",
    "        first_game = 0\n",
    "    else:\n",
    "        first_game = game_number-last_n_games-1\n",
    "\n",
    "    x_train = df.iloc[first_game:game_number-1,7:-1]\n",
    "    y_train = df.iloc[first_game:game_number-1,-1]\n",
    "\n",
    "    \n",
    "    x_test = df.iloc[game_number-1,7:-1]\n",
    "    y_test = df.iloc[game_number-1,-1]\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b80733-97da-42a8-8a64-48bcbb60dd3a",
   "metadata": {},
   "source": [
    "# 2. Models and Algorithm\n",
    "\n",
    "In this section many classification algorithms are going to be coded in functions to call them during further prediction scenarios. Firstly the classification models codded as function to ease the coding the algorithm.\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae247ed1-45eb-4666-b416-973d3a486df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(x_train,x_test,y_train,y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "    \n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "    \n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1d302-a102-4d89-9641-476aa6ed8f4c",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5191ac-7ce4-45c1-bbb1-3abd521a1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(x_train,x_test,y_train,y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "\n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "\n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36bfd9-0c31-4515-8f09-19ac4f4b61d7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14d9007-e5a1-4b8d-9c6a-7af00f447700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "    y_train = y_train.astype('int')\n",
    "    y_test = y_test.astype('int')\n",
    "    \n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0,probability=True)\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "    \n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "    \n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec557936-baa8-4cbb-a4cc-a27e0daee9ac",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43ab8e1-ecb9-4bc1-89dc-7ba876c9f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(x_train,x_test,y_train,y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "    \n",
    "    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "    \n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7209044e-997e-4455-8549-1c09ace90861",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b272858e-84ea-4dd7-a432-f5010ea4e591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(x_train,x_test,y_train,y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "    \n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "    \n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98500cb5-d27c-47ea-9c30-737f8cde5781",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9316f371-69ad-4201-8fcc-36d2450b75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train,x_test,y_train,y_test):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    sc_y = StandardScaler()\n",
    "    X = sc_X.fit_transform(x_train.values)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X, y_train)\n",
    "\n",
    "    x_test_sca = sc_X.transform([x_test])\n",
    "    y_pred = classifier.predict(x_test_sca)\n",
    "    \n",
    "    prob = classifier.predict_proba(x_test_sca)\n",
    "    \n",
    "    return y_pred,y_test,prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb133e-7c8a-4186-be6c-6be76cd21e17",
   "metadata": {},
   "source": [
    "# Prediction Algorithm\n",
    "\n",
    "The idea behind prediction algoritm is basically using the opponent statistics as predictor varibles and the result of the game as response variable. This approach creates the necessity of training a separate model for each NBA team. By this aproach we are aiming to understand \"How Timberwolves perform against a team with XXX statistics during this season?\" and we are hoping to find how Timberwolves are going to perform next when we put the statistics of the next opponent in a classification model.\n",
    "\n",
    "Since the main motivation of this projects is to simulate real time predictions during an NBA season when we want to predict a game; for example 24th game of Timberwolves; we will only going to use the data before that game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc18835-e0d9-4f2a-a1fe-66f1825431b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_game(df,game_number,model,last_n_games=60):\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = get_train_test(df,game_number,last_n_games)\n",
    "    \n",
    "    if model == \"logistic_regression\":\n",
    "        y_pred,y_test,prob = logistic_regression(x_train,x_test,y_train,y_test)  \n",
    "    elif model == \"knn\":\n",
    "        y_pred,y_test,prob = knn(x_train,x_test,y_train,y_test)  \n",
    "    elif model == \"svm\":\n",
    "        y_pred,y_test,prob = svm(x_train,x_test,y_train,y_test)  \n",
    "    elif model == \"naive_bayes\":\n",
    "        y_pred,y_test,prob = naive_bayes(x_train,x_test,y_train,y_test)  \n",
    "    elif model == \"decision_tree\":\n",
    "        y_pred,y_test,prob = decision_tree(x_train,x_test,y_train,y_test)  \n",
    "    elif model == \"random_forest\":\n",
    "        y_pred,y_test,prob = random_forest(x_train,x_test,y_train,y_test)  \n",
    "    \n",
    "    return y_pred,y_test,prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8032b9-bc95-405f-b24c-00082680b84e",
   "metadata": {},
   "source": [
    "We are going to use another schedule dataset with whole calender (not like team by team like schedule_score.db). This dataset <<wholeSchedule_1230games.csv>> is gathered from \"www.basketball-reference.com\". A column named Game_Code added to match the data with another datasets in the future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23abce17-dd70-4f89-b5d2-1d3ea75e8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_games_scenario(first_game,last_game,model,last_n_games):\n",
    "    wholeSchedule = pd.read_csv(\"wholeSchedule_1230games.csv\")\n",
    "    wholeSchedule['Date'] = pd.to_datetime(wholeSchedule['Date'],format='%Y-%m-%d')\n",
    "    wholeSchedule = wholeSchedule.sort_values(by=\"Date\")\n",
    "    \n",
    "    prediction_results = []\n",
    "    \n",
    "    for index,row in wholeSchedule.iterrows():\n",
    "        \n",
    "        if index > first_game and index < last_game:\n",
    "            \n",
    "            # We need short team names like \"atl\",\"phi\", the Game_Code column is created as such {game_date}_{visitor_team}_{home_team}. Ex. 16102018_phi_bos\n",
    "            home_team = row[\"Game_Code\"].split(\"_\")[2]\n",
    "            visitor_team = row[\"Game_Code\"].split(\"_\")[1]\n",
    "            date = pd.to_datetime(row[\"Game_Code\"].split(\"_\")[0],format='%d%m%Y') \n",
    "\n",
    "            home_df = datasets[home_team]\n",
    "            visitor_df = datasets[visitor_team]\n",
    "            \n",
    "            # We are going to make prediction with both team's models and then we are going to compare the results.\n",
    "            # Home team prediction with SVM\n",
    "            game_number_for_home_team = home_df[home_df[\"Date\"] == date][\"Game\"].values[0]\n",
    "            y_pred_home,y_test_home,prob_home = predict_game(home_df,game_number_for_home_team,model,last_n_games)\n",
    "            \n",
    "            # Visitor team prediction with SVM\n",
    "            game_number_for_visitor_team = visitor_df[visitor_df[\"Date\"] == date][\"Game\"].values[0]\n",
    "            y_pred_visitor,y_test_visitor,prob_visitor = predict_game(visitor_df,game_number_for_visitor_team,model,last_n_games)\n",
    "            \n",
    "            prediction_results.append([y_pred_home,y_test_home,max(prob_home[0]),y_pred_visitor,y_test_visitor,max(prob_visitor[0])])\n",
    "        \n",
    "    return prediction_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40604e-630a-426b-8b44-b1ca49480036",
   "metadata": {},
   "source": [
    "# 3. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c66450-72bf-4379-b76c-ff154cc9ade4",
   "metadata": {},
   "source": [
    "We are going to start the application by simulating the prediction model in the middle of the season. We are going to start prediction after 550 games have played to gather enough data and we will not make prediction for last 80 games since some teams have different motivations at the end of the season like tanking or resting for play-offs. We are going to simulate each model and will compare their performanses. Also we are going to test if models of the both  home and visitor teams are going predict same results and how the correct guess ratio will change if we apply the condition of both model should predict the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3243fb74-5363-4673-834f-ece82f176e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  logistic_regression\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       448\n",
      "Same predictions by both models and correct: 316 (70.54%)\n",
      "-------------------------------------------------------------\n",
      "Model:  knn\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       398\n",
      "Same predictions by both models and correct: 263 (66.08%)\n",
      "-------------------------------------------------------------\n",
      "Model:  svm\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       435\n",
      "Same predictions by both models and correct: 305 (70.11%)\n",
      "-------------------------------------------------------------\n",
      "Model:  naive_bayes\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       429\n",
      "Same predictions by both models and correct: 297 (69.23%)\n",
      "-------------------------------------------------------------\n",
      "Model:  decision_tree\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       353\n",
      "Same predictions by both models and correct: 228 (64.59%)\n",
      "-------------------------------------------------------------\n",
      "Model:  random_forest\n",
      "Total games:                                 599\n",
      "*****\n",
      "Total same predictions by both models:       418\n",
      "Same predictions by both models and correct: 277 (66.27%)\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = [\"logistic_regression\",\"knn\",\"svm\",\"naive_bayes\",\"decision_tree\",\"random_forest\"]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    same_predictions = 0\n",
    "    same_and_correct_predictions = 0\n",
    "\n",
    "    total_games = 0\n",
    "    \n",
    "    print(\"Model: \",model)\n",
    "    \n",
    "    # We are going start predicting after 550 games have played and we will not going to predict last 80 games since most of the teams have \n",
    "    # different motives at the end of the season like tanking or resting key players.\n",
    "    prediction_results = predict_games_scenario(first_game=550,last_game=1150,model=model,last_n_games=60)\n",
    "    # prediction_results = [[y_pred_home,y_test_home,prob_home,y_pred_visitor,y_test_visitor,prob_visitor]]\n",
    "    predictions_df = pd.DataFrame(prediction_results,columns=[\"Y_pred_home\",\"Y_test_home\",\"Prob_home\",\"Y_pred_visitor\",\"Y_test_visitor\",\"Prob_visitor\"])\n",
    "    \n",
    "    \n",
    "    # We are going to check for different values that means models have same prediction about winner.\n",
    "    # Ex. y_pred_home = 0 and y_pred_visitor = 1; both of these predict that visitor team will win the game\n",
    "    for index,row in predictions_df.iterrows():\n",
    "        if row[\"Y_pred_home\"] != row[\"Y_pred_visitor\"]:\n",
    "            same_predictions+=1\n",
    "            # Counting correct guesses\n",
    "            if row[\"Y_pred_home\"] == row[\"Y_test_home\"]:\n",
    "                same_and_correct_predictions += 1\n",
    "\n",
    "         \n",
    "        total_games += 1\n",
    "\n",
    "    print(\"Total games:                                 {0}\".format(total_games))\n",
    "    print(\"*****\")\n",
    "    print(\"Total same predictions by both models:       {0}\".format(same_predictions))\n",
    "    print(\"Same predictions by both models and correct: {0} ({1:.2f}%)\".format(same_and_correct_predictions,same_and_correct_predictions/same_predictions*100))\n",
    "    print(\"-------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da579e-36ca-4821-9da2-4eb819ec2114",
   "metadata": {},
   "source": [
    "As the results show logistic regression, support vector machine and naive bayes have the best correct guess ratio. In this project we have achieved around 70% correct guess ratio by keeping the conditions as much as same with real life. The downside of the algorithm is this solution is not a generic solution, it cannot be used to predict the first games of the season. In the next projects we will try to use this predictions to make a bet simulation and we are going to apply new classification models such as deep learning to improve the correct guess percentage also classification models that are used in this project can be optimized. This project was a quick implementation of the idea of opponent statistics based double checked prediction approach it can be improved a lot.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
